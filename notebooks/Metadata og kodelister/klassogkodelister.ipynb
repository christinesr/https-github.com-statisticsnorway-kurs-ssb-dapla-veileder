{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importerer bibliotek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her importeres nødvendige biblioteker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from ssb_sparktools.editing import editing as stedit\n",
    "from ssb_sparktools.editing import controls as stctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riktig KLASS-tabell velges ved å sette inn rett tabellnummer. Deretter velges dato. (Her velges dagens dato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#485\n",
    "klasstabell=484 \n",
    "klassdato = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leser inn KLASS tabell i json, xml og csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KLASS-tabellen kan leses inn i ulike formater. Her gis eksempler på å lese den inn som json-, csv- eller xml-fil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = requests.get(f'https://data.ssb.no/api/klass/v1/classifications/{klasstabell}/codesAt.json?date={klassdato}').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_csv = requests.get(f'https://data.ssb.no/api/klass/v1/classifications/{klasstabell}/codesAt.csv?date={klassdato}&csvSeparator=;'\\\n",
    "                            , headers={'accept':'text/csv','charset':'UTF-8'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_xml = requests.get(f'https://data.ssb.no/api/klass/v1/classifications/{klasstabell}/codesAt?date={klassdato}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLASS json til pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En KLASS-json-fil kan gjøres om til en Pandas-dataframe på denne måten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_response_json = pd.DataFrame(response_json['codes'])\n",
    "pd_response_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLASS csv to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En KLASS-csv kan gjøres om til en Pands-dataframe på denne måten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_response_csv = pd.read_csv(filepath_or_buffer = io.StringIO(response_csv), sep=';')\n",
    "pd_response_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLASS json til spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksempel på hvordan man kan gjøre om en KLASS-json-fil til en Spark-dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "kodeliste_variabler = [StructField('code', StringType(), True),\\\n",
    "                   StructField('parentCode', StringType(), True),\\\n",
    "                   StructField('level', StringType(), True),\\\n",
    "                   StructField('name', StringType(), True),\\\n",
    "                   StructField('shortName', StringType(), True),\\\n",
    "                  StructField('presentationName', StringType(), True)]\n",
    "kodeliste_schema = StructType(kodeliste_variabler)\n",
    "\n",
    "rdd_kodeliste = sc.parallelize(response_json['codes'])\n",
    "df_kodeliste = sqlContext.createDataFrame(rdd_kodeliste, kodeliste_schema)\n",
    "df_kodeliste.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLASS csv til spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksempel på hvordan man kan gjøre om en KLASS-csv-fil til en Spark-dataframe (<b> spark_csv</b>, som vil benyttes i eksempelet under):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvData = sc.parallelize(response_csv.split(\"\\n\"))\n",
    "spark_csv = spark.read.csv(csvData, sep=';', header=True)\n",
    "spark_csv.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLASS xml til spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksempel på hvordan man kan gjøre om en KLASS-xml-fil til en Spark-dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlData = sc.parallelize(response_xml.text.split(\"\\n\"))\n",
    "spark_xml = spark.read.csv(xmlData, sep=',', header=True, multiLine=True)\n",
    "spark_xml.show(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lager testdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her lages testdata <b>df_spark</b> til bruk i eksemplene under:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'ptype': 'alderspensjonFraFolketrygden', 'ant': 2}, {'ptype':'krigspensjon', 'ant': 20}, {'ptype':'feilkode', 'ant': 200}]\n",
    "df = pd.DataFrame(data)\n",
    "df_spark = spark.createDataFrame(df)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodelistesjekk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksempel på sjekk av koder: lager først en liste med alle kodene fra csv-filen <b>df_kodeliste</b>. Deretter brukes funksjonen _listcode_check_ fra _SSB Spark tools_ til å sjekke kodene i variabelen <b>ptype</b> i dataframen <b>df_spark</b> opp mot kodene i <b>df_kodeliste</b>. Denne gir beskjed dersom ikke alle kodene ligger i kodelista (den boolske verdien <b>checkres</b> blir \"False\" dersom det finnes en eller flere koder som ikke matcher med kodelista). Dersom en ønsker å se hvilke(n) kode(r) som ikke ligger på kodelista, kan man printe ut dataframen <b>df_res</b>, som under: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kodeliste = []\n",
    "for row in spark_csv.rdd.collect():\n",
    "    df_kodeliste.append(row['code'])\n",
    "\n",
    "checkres, df_res  = stctrl.listcode_check(df_spark, 'ptype', df_kodeliste)\n",
    "if not (checkres):\n",
    "    print('Ikke alle kodene var i kodelisten, sjekk returnert dataframe for detaljer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodelisteoppslag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her brukes funksjonen _listcode_lookup_ fra _SSB_Spark_tools_ til å legge på navnet på den aktuelle koden fra kodelista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp = stedit.listcode_lookup(df_spark, 'ptype', spark_csv, ['code', 'name'])\n",
    "df_lp.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark (k8s cluster)",
   "language": "python",
   "name": "pyspark_k8s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
