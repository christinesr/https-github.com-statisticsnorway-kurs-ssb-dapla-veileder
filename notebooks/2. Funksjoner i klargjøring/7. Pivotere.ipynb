{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivotere\n",
    "<font size=2>Funksjonen å \"vrenge\" variabler om til enheter og omvendt.\n",
    "\n",
    "Pivot-funksjonen i pyspark:\n",
    "<code>pivote</code>: <i>Pivot a column of the GroupedData and perform the specified aggregation. There are two versions of pivot function: one that requires the caller to specify the list of distinct values to pivot on, and one that does not. The latter is more concise but less efficient, because Spark needs to first compute the list of distinct values internally.</i> [spark.apache.org/pivot](https://spark.apache.org/docs/latest/api/R/pivot.html)\n",
    "\n",
    "<code>df.groupBy(grouping_columns).pivot(pivot_column,[values]) agg(aggregate_expressions)</code>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importere biblioteker (kode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leser inn eksempeldatasett (kode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_land_innbyggerantall_2018  = spark.read.path(\"/felles/veiledning/pyspark/eksempler/innbyggerantall/2018\")\n",
    "df_land_innbyggerantall_2017  = spark.read.path(\"/felles/veiledning/pyspark/eksempler/innbyggerantall/2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lager sammensatt datasett til bruk i pivoteringseksempel (kode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_land_innbyggerantall_2018_2017 = df_land_innbyggerantall_2018.unionByName(df_land_innbyggerantall_2017)\n",
    "df_land_innbyggerantall_2018_2017.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoterer datasett (kode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_land_og_innbyggere = df_land_innbyggerantall_2018_2017.drop(\"Landkode\",\"Kilde\")\n",
    "df_vrengt = df_land_og_innbyggere.groupBy(\"År\").pivot((\"Land\")).sum(\"Innbyggerantall\")\n",
    "df_land_og_innbyggere.show()\n",
    "df_vrengt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark (local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
