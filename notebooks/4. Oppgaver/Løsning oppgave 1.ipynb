{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 1: Finne landene med høyeste og laveste befolkningstetthet\n",
    "Hint: Se eksemplet i veilederen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laster inn bibliotek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1  Finne og leses inn datasett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skriv koden for å finne og lese inn datasettene om innbyggerantall 2020 og areal\n",
    "spark.read.path(\"/felles/veiledning/pyspark/eksempler*\").show(10, False)\n",
    "\n",
    "df_areal = spark.read.path(\"/felles/veiledning/pyspark/eksempler/areal\")\n",
    "df_innbyggerantall_2020 = spark.read.path(\"/felles/veiledning/pyspark/eksempler/innbyggerantall/2020\")\n",
    "print(\"*********************************** AREAL ***********************************\")\n",
    "df_areal.show(50,False)\n",
    "print(\"*********************************** INNBYGGERANTALL 2020 ***********************************\")\n",
    "df_innbyggerantall_2020.show(50,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Fjerne dubletter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skriv kode for å sjekke og evt. fjerne dubletter\n",
    "\n",
    "#Sorterer etter land og innbyggerantall og lister ut den sorterte dataframen\n",
    "print(\"*********************************** INNBYGGERANTALL SORTERT ETTER LAND OG INNBYGGERANTALL ***********************************\")\n",
    "\n",
    "df_innbyggerantall_2020_sort = df_innbyggerantall_2020.orderBy(['Land','Innbyggerantall'])\n",
    "df_innbyggerantall_2020_sort.show(50,False)\n",
    "\n",
    "\n",
    "#Tar ut oversikt over de radene med likt \"land\" som forekommer flere enn en gang i dataframen, og sånn sett utgjør den samlede mengden av duplikater\n",
    "df_land_dub_alle  = df_innbyggerantall_2020_sort.join(df_innbyggerantall_2020_sort.groupBy('Land')\\\n",
    "          .count().where('count = 1').drop('count'),\n",
    "          on=['Land'],\n",
    "          how='left_anti')\n",
    "print(\"*********************************** OVERSIKT OVER DUPLIKATER ***********************************\")\n",
    "df_land_dub_alle.show()  \n",
    "\n",
    "#Velger den siste duplikaten\n",
    "#Overfører df_land_dub_alle til pandas dataframe (pdf)\n",
    "pdf = df_innbyggerantall_2020_sort.toPandas()\n",
    "df_pdf_udub = pdf.drop_duplicates(subset=['Land'], keep='last', inplace=False)\n",
    "\n",
    "#Overfører \"tilbake\" til spark dataframe\n",
    "schema_land_innbyggerantall_2020 = StructType([\\\n",
    "    StructField('Land',StringType(), False),\\\n",
    "    StructField('Landkode',StringType(), False),\\\n",
    "    StructField('Innbyggerantall', IntegerType(), False),\\\n",
    "    StructField('År', IntegerType(), False),\\\n",
    "    StructField('Kilde', StringType(), False)])\n",
    "\n",
    "df_innbyggere_udub = spark.createDataFrame(df_pdf_udub,  schema_land_innbyggerantall_2020)\n",
    "print(\"*********************************** DATASETTET UTEN DUBLETTER ***********************************\")\n",
    "df_innbyggere_udub.show(50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skriv kode for å sjekke og evt. fjerne dubletter\n",
    "\n",
    "#Sorterer etter land og areal og lister ut den sorterte dataframen\n",
    "print(\"*********************************** AREALDATASETT SORTERT ETTER LAND OG AREAL ***********************************\")\n",
    "\n",
    "df_areal_sort = df_areal.orderBy(['Land','Areal'])\n",
    "df_areal_sort.show(50,False)\n",
    "\n",
    "\n",
    "#Tar ut oversikt over de radene med likt \"land\" som forekommer flere enn en gang i dataframen, og sånn sett utgjør den samlede mengden av duplikater\n",
    "df_areal_dub_alle  = df_areal_sort.join(df_areal_sort.groupBy('Land')\\\n",
    "          .count().where('count = 1').drop('count'),\n",
    "          on=['Land'],\n",
    "          how='left_anti')\n",
    "print(\"*********************************** OVERSIKT OVER DUPLIKATER ***********************************\")\n",
    "df_areal_dub_alle.show()  \n",
    "\n",
    "#Velger den siste duplikaten\n",
    "#Overfører df_land_dub_alle til pandas dataframe (pdf)\n",
    "pdf2 = df_areal_sort.toPandas()\n",
    "df_pdf2_udub = pdf2.drop_duplicates(subset=['Land'], keep='first', inplace=False)\n",
    "\n",
    "#Overfører \"tilbake\" til spark dataframe\n",
    "schema_areal = StructType([\\\n",
    "    StructField('Land',StringType(), False),\\\n",
    "    StructField('Areal', IntegerType(), False),\\\n",
    "    StructField('Årstall', IntegerType(), False),\\\n",
    "    StructField('Landkode',StringType(), False),\\\n",
    "    StructField('Kilde', StringType(), False)])\n",
    "\n",
    "df_areal_udub = spark.createDataFrame(df_pdf2_udub,  schema_areal)\n",
    "print(\"*********************************** DATASETTET UTEN DUBLETTER ***********************************\")\n",
    "df_areal_udub.show(50,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Koble datasett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skriv kode for å koble sammen datasettene (innbyggerantall og areal)\n",
    "df_areal_innbyggerantall = df_areal_udub.join(df_innbyggere_udub, 'Land', 'inner')\n",
    "df_areal_innbyggerantall.show(50,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Lage en ny variabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skriv kode for å lage en ny variabel for befolkningstetthet\n",
    "df_areal_innbyggerantall = df_areal_innbyggerantall.withColumn('Befolkningstetthet',df_areal_innbyggerantall['Innbyggerantall']/df_areal_innbyggerantall['Areal'])\n",
    "df_areal_innbyggerantall.show(50,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Finne maks og min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skrive kode for å finne maks og min av befokningstetthet\n",
    "from pyspark.sql.functions import mean, min, max\n",
    "result = df_areal_innbyggerantall.select([min(\"Befolkningstetthet\"), max(\"Befolkningstetthet\")])\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark (local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
